{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json as j\n",
    "import numpy as np\n",
    "\n",
    "# Import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = os.path.dirname(\"\")\n",
    "with open(os.path.join(path_dir, 'timeseries_pheno_metrics.json')) as f:\n",
    "    json = j.load(f)\n",
    "    f.close()\n",
    "\n",
    "X_train = json[\"timeseries_pheno_metrics\"]\n",
    "y_train = json[\"label_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = []\n",
    "new_y_train = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if int(y_train[i]) == 370:\n",
    "        new_X_train.append(X_train[i])\n",
    "        new_y_train.append(y_train[i])\n",
    "    if int(y_train[i]) == 372:\n",
    "        new_X_train.append(X_train[i])\n",
    "        new_y_train.append(y_train[i])\n",
    "    if int(y_train[i]) == 365:\n",
    "        new_X_train.append(X_train[i])\n",
    "        new_y_train.append(y_train[i])\n",
    "    if int(y_train[i]) == 359:\n",
    "        new_X_train.append(X_train[i])\n",
    "        new_y_train.append(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert data to PyTorch tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([494, 1, 41])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(np.expand_dims(new_X_train, axis=1), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(new_y_train, dtype=torch.long)\n",
    "\n",
    "print(X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM classifier model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_tensor.shape[2]\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "output_size = len(set(y_train_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(input_size, hidden_size, num_layers, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cshd import cube_query, get_timeseries, params_phenometrics, calc_phenometrics, cshd_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_class_by_id(id):\n",
    "    if 370: return \"Soja\"\n",
    "    if 372: return \"Arroz\"\n",
    "    if 359: return \"Vegetação Florestal\"\n",
    "    if 365: return \"Corpos d'agua\"\n",
    "    if 367: return \"Superfícies Artificiais\"\n",
    "    if 363: return \"Pastagem\"\n",
    "    if 361: return \"Formação Campestre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising calculation of phenometrics.\n",
      "\n",
      "Beginning extraction of CRS metadata.\n",
      "> Extracting CRS metadata.\n",
      "> No CRS metadata found. Returning None.\n",
      "\n",
      "Beginning calculation of phenometrics. This can take awhile - please wait.\n",
      "\n",
      "Beginning calculation of peak of season (pos) values and times.\n",
      "> Calculating peak of season (pos) values.\n",
      "> Calculating peak of season (pos) times.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of valley of season (vos) values and times.\n",
      "> Calculating valley of season (vos) values.\n",
      "> Calculating valley of season (vos) times.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of middle of season (mos) values (times not possible).\n",
      "> Calculating middle of season (mos) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of base (bse) values (times not possible).\n",
      "> Calculating base (bse) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of amplitude of season (aos) values (times not possible).\n",
      "> Calculating amplitude of season (aos) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of start of season (sos) values and times.\n",
      "> Calculating start of season (sos) values via method: seasonal_amplitude.\n",
      "> Calculating start of season (sos) times via method: seasonal_amplitude.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of end of season (eos) values and times.\n",
      "> Calculating end of season (eos) values via method: seasonal_amplitude.\n",
      "> Calculating end of season (eos) times via method: seasonal_amplitude.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of length of season (los) values (times not possible).\n",
      "> Calculating length of season (los) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of rate of increase (roi) values (times not possible).\n",
      "> Calculating rate of increase (roi) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of rate of decrease (rod) values (times not possible).\n",
      "> Calculating rate of decrease (rod) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of long integral of season (lios) values (times not possible).\n",
      "> Calculating long integral of season (lios) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of short integral of season (sios) values (times not possible).\n",
      "> Calculating short integral of season (sios) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of long integral of total (liot) values (times not possible).\n",
      "> Calculating long integral of total (liot) values.\n",
      "> Success!\n",
      "\n",
      "Beginning calculation of short integral of total (siot) values (times not possible).\n",
      "> Calculating short integral of total (siot) values.\n",
      "> Success!\n",
      "\n",
      "Beginning addition of CRS metadata.\n",
      "> Adding CRS metadata.\n",
      "> Could not add CRS metadata to data. Aborting.\n",
      "\n",
      "Phenometrics calculated successfully!\n",
      "<xarray.Dataset> Size: 72B\n",
      "Dimensions:      ()\n",
      "Data variables: (12/18)\n",
      "    pos_values   float32 4B 8.187e+03\n",
      "    pos_times    float32 4B 17.0\n",
      "    mos_values   float32 4B 7.589e+03\n",
      "    vos_values   float32 4B -9.999e+03\n",
      "    vos_times    float32 4B 49.0\n",
      "    bse_values   float32 4B -1.2e+03\n",
      "    ...           ...\n",
      "    roi_values   float32 4B 36.75\n",
      "    rod_values   float32 4B 568.3\n",
      "    lios_values  float32 4B 1.003e+04\n",
      "    sios_values  float32 4B 4.503e+04\n",
      "    liot_values  float32 4B 3.954e+04\n",
      "    siot_values  float32 4B 2.595e+05\n"
     ]
    }
   ],
   "source": [
    "S2_cube = cube_query(\n",
    "    collection=\"S2-16D-2\",\n",
    "    start_date=\"2023-01-01\",\n",
    "    end_date=\"2023-12-31\",\n",
    "    freq='16D',\n",
    "    band=\"NDVI\"\n",
    ")\n",
    "\n",
    "config = params_phenometrics(\n",
    "    peak_metric='pos', \n",
    "    base_metric='vos', \n",
    "    method='seasonal_amplitude', \n",
    "    factor=0.2, \n",
    "    thresh_sides='two_sided', \n",
    "    abs_value=0.1\n",
    ")\n",
    "\n",
    "longitude = -52.97612606396396\n",
    "latitude =  -29.325361867915753\n",
    "\n",
    "ts = get_timeseries(\n",
    "    cube=S2_cube, \n",
    "    geom=[dict(coordinates = [longitude, latitude])],\n",
    "    cloud_filter = True\n",
    ")\n",
    "ndvi_array = cshd_array(\n",
    "    timeserie=ts['values'],\n",
    "    start_date='2023-01-01',\n",
    "    freq='16D'\n",
    ")\n",
    "ds_phenos = calc_phenometrics(\n",
    "    da=ndvi_array,\n",
    "    engine='phenolopy',\n",
    "    config=config,\n",
    "    start_date='2023-01-01'\n",
    ")\n",
    "test_tl = ts['values'] + ds_phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: tensor(359) Soja\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(np.expand_dims([test_tl], axis=1), dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    predicted_labels = torch.argmax(predictions, dim=1)\n",
    "    print(\"Predicted Label:\", predicted_labels[0], return_class_by_id(predicted_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_dir, 'test_timeseries_pheno_metrics.json')) as ff:\n",
    "    json_test = j.load(ff)\n",
    "    ff.close()\n",
    "\n",
    "X_test = json_test[\"timeseries_pheno_metrics\"]\n",
    "y_test = json_test[\"label_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = []\n",
    "new_y_test = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if int(y_test[i]) == 370:\n",
    "        new_X_test.append(X_test[i])\n",
    "        new_y_test.append(y_test[i])\n",
    "    if int(y_test[i]) == 372:\n",
    "        new_X_test.append(X_test[i])\n",
    "        new_y_test.append(y_test[i])\n",
    "    if int(y_test[i]) == 365:\n",
    "        new_X_test.append(X_test[i])\n",
    "        new_y_test.append(y_test[i])\n",
    "    if int(y_test[i]) == 359:\n",
    "        new_X_test.append(X_test[i])\n",
    "        new_y_test.append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 41])\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(np.expand_dims(new_X_test, axis=1), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(new_y_test, dtype=torch.long)\n",
    "\n",
    "print(X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    predicted_labels = torch.argmax(predictions, dim=1)\n",
    "\n",
    "correct_count = sum(a == b for a, b in zip(y_test_tensor, predicted_labels))\n",
    "overlap = float(correct_count) / len(y_test_tensor) * 100\n",
    "\n",
    "float(overlap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
